version: "3.9"

services:
  caddy:
    image: caddy:2
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile
      - caddy_data:/data
      - caddy_config:/config

  api:
    image: ghcr.io/aniketbansod/ai-project-backend:prod-latest
    env_file: backend.env
    depends_on:
      - ai
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 5s
      retries: 3

  worker:
    image: ghcr.io/aniketbansod/ai-project-worker:prod-latest
    env_file: backend.env
    depends_on:
      - api
      - ai
    restart: unless-stopped

  ai:
    image: ghcr.io/aniketbansod/ai-service:prod-latest
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 5s
      retries: 3
    volumes:
      - ai_index:/app/backend/src
      - hf_cache:/root/.cache/huggingface

volumes:
  ai_index:
  hf_cache:
  caddy_data:
  caddy_config:
