version: "3.9"

services:
  caddy:
    image: caddy:2.8.4
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - caddy_data:/data
      - caddy_config:/config
      - ./Caddyfile:/etc/caddy/Caddyfile:ro

  api:
    image: ghcr.io/aniketbansod/ai-project-backend:latest
    restart: unless-stopped
    env_file:
      - ./backend/.env
    depends_on:
      - ai
    healthcheck:
      test:
        [
          "CMD-SHELL",
          'node -e "require(''http'').get(''http://localhost:5000/health'', r=>process.exit(r.statusCode===200?0:1)).on(''error'',()=>process.exit(1))"',
        ]
      interval: 30s
      timeout: 5s
      retries: 5

  worker:
    image: ghcr.io/aniketbansod/ai-project-worker:latest
    restart: unless-stopped
    env_file:
      - ./backend/.env
    command: ["node", "dist/src/worker.js"]
    depends_on:
      - api

  ai:
    image: ghcr.io/aniketbansod/ai-project-ai:latest
    restart: unless-stopped
    volumes:
      - ai_index:/app/backend/src
      - hf_cache:/root/.cache/huggingface
    env_file:
      - ./backend/.env
    environment:
      - DATABASE_URL=${DIRECT_URL}
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "python - <<'PY'\nimport sys,urllib.request\ntry:\n  with urllib.request.urlopen('http://localhost:8000/', timeout=3) as r:\n    sys.exit(0 if r.status==200 else 1)\nexcept Exception:\n  sys.exit(1)\nPY",
        ]
      interval: 30s
      timeout: 10s
      retries: 5

volumes:
  caddy_data:
  caddy_config:
  ai_index:
  hf_cache:
